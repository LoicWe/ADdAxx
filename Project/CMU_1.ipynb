{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'graph_tool', 'wurlitzer'}\n",
      "Note: to be able to use all bipartite methods, you need to install some additional packages:  {'wurlitzer'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cdlib import viz\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas_profiling\n",
    "import networkx as nx\n",
    "from cdlib import algorithms, viz\n",
    "from difflib import get_close_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from tsv file to a pandas dataframe\n",
    "movies_metadata = pd.read_csv('MovieSummaries/movie.metadata.tsv', sep='\\t', header=None)\n",
    "character_metadata = pd.read_csv('MovieSummaries/character.metadata.tsv', sep='\\t', header=None)\n",
    "plot_summaries = pd.read_csv('MovieSummaries/plot_summaries.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns have the following labels:\n",
    "<br> Movies metadata:\n",
    "1. Wikipedia movie ID\n",
    "2. Freebase movie ID\n",
    "3. Movie name\n",
    "4. Movie release date\n",
    "5. Movie box office revenue\n",
    "6. Movie runtime\n",
    "7. Movie languages (Freebase ID:name tuples)\n",
    "8. Movie countries (Freebase ID:name tuples)\n",
    "9. Movie genres (Freebase ID:name tuples)\n",
    "\n",
    "Character/actors metadata:\n",
    "1. Wikipedia movie ID\n",
    "2. Freebase movie ID\n",
    "3. Movie release date\n",
    "4. Character name\n",
    "5. Actor date of birth\n",
    "6. Actor gender\n",
    "7. Actor height (in meters)\n",
    "8. Actor ethnicity (Freebase ID)\n",
    "9. Actor name\n",
    "10. Actor age at movie release\n",
    "11. Freebase character/actor map ID\n",
    "12. Freebase character ID\n",
    "13. Freebase actor ID\n",
    "\n",
    "Plot summaries:\n",
    "1. Wikipedia movie ID\n",
    "2. Plot summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label the columns\n",
    "movies_metadata.columns = ['Wikipedia_movie_ID', 'Freebase_movie_ID', 'Movie_name', 'Movie_release_date', 'Movie_box_office_revenue', 'Movie_runtime', 'Movie_languages', 'Movie_countries', 'Movie_genres'] \n",
    "character_metadata.columns = ['Wikipedia_movie_ID', 'Freebase_movie_ID', 'Movie_release_date', 'Character_name', 'Actor_date_of_birth', 'actor_gender', 'Actor_height_(in_meters)', 'Actor_ethnicity', 'Actor_name', 'Actor_age_at_movie_release', 'Freebase_character/actor_map_ID', 'Freebase_character_ID', 'Freebase_actor_ID']\n",
    "plot_summaries.columns = ['Wikipedia_movie_ID', 'Plot_summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Visualizing row data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Movie_box_office_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_languages</th>\n",
       "      <th>Movie_countries</th>\n",
       "      <th>Movie_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25611</th>\n",
       "      <td>25446077</td>\n",
       "      <td>/m/09k6vxm</td>\n",
       "      <td>Paraguayan Hammock</td>\n",
       "      <td>2006-05-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{\"/m/0f8l9c\": \"France\", \"/m/0h7x\": \"Austria\", ...</td>\n",
       "      <td>{\"/m/04xvlr\": \"Period piece\", \"/m/07s9rl0\": \"D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54237</th>\n",
       "      <td>6038556</td>\n",
       "      <td>/m/0flx6r</td>\n",
       "      <td>An Evening with Kevin Smith 2: Evening Harder</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/0jtdp\": \"Documentary\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69307</th>\n",
       "      <td>26183882</td>\n",
       "      <td>/m/0b74m8v</td>\n",
       "      <td>A Cricket in the Ear</td>\n",
       "      <td>1976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{\"/m/015qh\": \"Bulgaria\"}</td>\n",
       "      <td>{\"/m/05p553\": \"Comedy film\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia_movie_ID Freebase_movie_ID  \\\n",
       "25611            25446077        /m/09k6vxm   \n",
       "54237             6038556         /m/0flx6r   \n",
       "69307            26183882        /m/0b74m8v   \n",
       "\n",
       "                                          Movie_name Movie_release_date  \\\n",
       "25611                             Paraguayan Hammock         2006-05-18   \n",
       "54237  An Evening with Kevin Smith 2: Evening Harder               2006   \n",
       "69307                           A Cricket in the Ear               1976   \n",
       "\n",
       "       Movie_box_office_revenue  Movie_runtime  \\\n",
       "25611                       NaN           76.0   \n",
       "54237                       NaN          239.0   \n",
       "69307                       NaN           95.0   \n",
       "\n",
       "                          Movie_languages  \\\n",
       "25611                                  {}   \n",
       "54237  {\"/m/02h40lc\": \"English Language\"}   \n",
       "69307                                  {}   \n",
       "\n",
       "                                         Movie_countries  \\\n",
       "25611  {\"/m/0f8l9c\": \"France\", \"/m/0h7x\": \"Austria\", ...   \n",
       "54237          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "69307                           {\"/m/015qh\": \"Bulgaria\"}   \n",
       "\n",
       "                                            Movie_genres  \n",
       "25611  {\"/m/04xvlr\": \"Period piece\", \"/m/07s9rl0\": \"D...  \n",
       "54237                        {\"/m/0jtdp\": \"Documentary\"}  \n",
       "69307                       {\"/m/05p553\": \"Comedy film\"}  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_metadata.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Character_name</th>\n",
       "      <th>Actor_date_of_birth</th>\n",
       "      <th>actor_gender</th>\n",
       "      <th>Actor_height_(in_meters)</th>\n",
       "      <th>Actor_ethnicity</th>\n",
       "      <th>Actor_name</th>\n",
       "      <th>Actor_age_at_movie_release</th>\n",
       "      <th>Freebase_character/actor_map_ID</th>\n",
       "      <th>Freebase_character_ID</th>\n",
       "      <th>Freebase_actor_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128046</th>\n",
       "      <td>7246171</td>\n",
       "      <td>/m/025x44p</td>\n",
       "      <td>2005-05-12</td>\n",
       "      <td>Joel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alistair Freeland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0l2yj9d</td>\n",
       "      <td>/m/0l2yj9h</td>\n",
       "      <td>/m/0l2yj9q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253520</th>\n",
       "      <td>12082059</td>\n",
       "      <td>/m/02vp6n1</td>\n",
       "      <td>1971</td>\n",
       "      <td>Andy Hobart</td>\n",
       "      <td>1939-10-22</td>\n",
       "      <td>M</td>\n",
       "      <td>1.85</td>\n",
       "      <td>/m/041rx</td>\n",
       "      <td>Tony Roberts</td>\n",
       "      <td>31.0</td>\n",
       "      <td>/m/03l0333</td>\n",
       "      <td>/m/0ch7lmt</td>\n",
       "      <td>/m/089_fl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317061</th>\n",
       "      <td>29588452</td>\n",
       "      <td>/m/0fpgc26</td>\n",
       "      <td>2011-05-16</td>\n",
       "      <td>Yvonne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yvonne Maalouf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0gm7dl4</td>\n",
       "      <td>/m/0gm7dl0</td>\n",
       "      <td>/m/0gm7dl2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Wikipedia_movie_ID Freebase_movie_ID Movie_release_date  \\\n",
       "128046             7246171        /m/025x44p         2005-05-12   \n",
       "253520            12082059        /m/02vp6n1               1971   \n",
       "317061            29588452        /m/0fpgc26         2011-05-16   \n",
       "\n",
       "       Character_name Actor_date_of_birth actor_gender  \\\n",
       "128046           Joel                 NaN            M   \n",
       "253520    Andy Hobart          1939-10-22            M   \n",
       "317061         Yvonne                 NaN            F   \n",
       "\n",
       "        Actor_height_(in_meters) Actor_ethnicity         Actor_name  \\\n",
       "128046                       NaN             NaN  Alistair Freeland   \n",
       "253520                      1.85        /m/041rx       Tony Roberts   \n",
       "317061                       NaN             NaN     Yvonne Maalouf   \n",
       "\n",
       "        Actor_age_at_movie_release Freebase_character/actor_map_ID  \\\n",
       "128046                         NaN                      /m/0l2yj9d   \n",
       "253520                        31.0                      /m/03l0333   \n",
       "317061                         NaN                      /m/0gm7dl4   \n",
       "\n",
       "       Freebase_character_ID Freebase_actor_ID  \n",
       "128046            /m/0l2yj9h        /m/0l2yj9q  \n",
       "253520            /m/0ch7lmt         /m/089_fl  \n",
       "317061            /m/0gm7dl0        /m/0gm7dl2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_metadata.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Plot_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15300</th>\n",
       "      <td>7427038</td>\n",
       "      <td>A colossal series of disasters releases someth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>170858</td>\n",
       "      <td>In December 1958, Norville Barnes, a business ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23504</th>\n",
       "      <td>27036009</td>\n",
       "      <td>Ranga  is son of Teacher . His friend is Vasu ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia_movie_ID                                       Plot_summary\n",
       "15300             7427038  A colossal series of disasters releases someth...\n",
       "1325               170858  In December 1958, Norville Barnes, a business ...\n",
       "23504            27036009  Ranga  is son of Teacher . His friend is Vasu ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_summaries.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Understanding and cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Exploring raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the pandas_profiling librarie to get a first rapid overview of the data. It gives many information like value repartition, correlations and missing values.\n",
    "<br>It ouptput the `character_metadata_report.html` and `movies_metadata_report.html` which can be found in the repo and doesn't requierd to re-run every time so we comment it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # profile the movies metadata dataframe\n",
    "# movies_metadata.profile_report(title='Movies Metadata Report')\n",
    "# # show the profile report\n",
    "# movies_metadata.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # profile the character metadata dataframe\n",
    "# character_metadata.profile_report(title='Character Metadata Report')\n",
    "# # show the profile report\n",
    "# character_metadata.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remark that for movies the `Movie_box_office_revenue`, `Movie_runtime` columns have some missing values and we face the same problems with those columns `Character_name`, `Actor_date_of_birth`, `Actor_height_(in_meters)`, `Actor_ethnicity` in the actor dataset. We'll probably not use most of them except for the boxoffice revenue and the ethnicity who could be interresting but will need some scarping to add missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to create a network between actors as nodes and movies as edges. Therfore we need to match those two different dataframes. The `Wikipedia_movie_ID` and `Freebase_movie_ID` are perfect for that as they have no missing values. <br>\n",
    "Furthermore we choose to use `Actor_name` as identifier for the actors as it is more understandable than the Freebase ID. As we will use it as identifier we will need to assure us that each Actor_name relates to a unique actor. And we also want to check if there is some typos in the actor names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstly filter actors_name\n",
    "character_metadata = character_metadata.dropna(subset=['Actor_name'])\n",
    "\n",
    "# create a dataframe referencing every actor_names\n",
    "actors_unique = character_metadata.drop_duplicates('Actor_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the typo question we tried a naiv way with the `get_close_matches` function which return us similar strings. \n",
    "But we have ~100'000 different names which take a lot of time but also gives way to much matches. The problem is that we should check them by hand which isn't possible. So we must find another way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for n in actors_unique.Actor_name:\n",
    "#     if type(n) == t:\n",
    "#         match = get_close_matches(n,actors_unique.Actor_name , cutoff=0.9)\n",
    "#         if len(match) > 1:\n",
    "#             print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we decided to use the Freebase ID to help us searching for typos. But we need to make the assumption that if there is a typo, both names will link to the same `Freebase_actor_ID`. <br>\n",
    "First we need to assure us that an actor links to a unique ID (we ignore the typo problem for now). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if every same actor_names refer to same actor_id\n",
    "# for a in actors_unique.Actor_name:\n",
    "#     same_name = character_metadata.query(\"`Actor_name` == @a\")\n",
    "#     if same_name.Freebase_actor_ID.nunique() > 1 & same_name.Actor_date_of_birth.nunique() > 1 & same_name.actor_gender.nunique() > 1:\n",
    "#         print(a, same_name.Freebase_actor_ID.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remark that some actors have the same `Actor_name` ! \n",
    "> This mean we can't us it as an identifier as we planned but we'll need to use the Freebase ID instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That said, let's continue our search for typos. <br>\n",
    "To test if an actor link to a unique ID we added the date of birth and gender information and it is sufficient to separate actors with same names. We now know that an actor link to only one ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then want to see if a Freebase ID link to more than one name which could be typos. We make the loop on the age column because same act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe referencing every actor_names\n",
    "actors_unique = character_metadata.drop_duplicates('Actor_name')\n",
    "actors_unique = actors_unique.dropna(subset=['Actor_name'])\n",
    "\n",
    "birth_unique = character_metadata.drop_duplicates('Actor_date_of_birth')\n",
    "\n",
    "actor_id_unique = character_metadata.drop_duplicates('Freebase_actor_ID')\n",
    "for i in actor_id_unique.Freebase_actor_ID:\n",
    "    same_name = character_metadata.query(\"`Freebase_actor_ID` == @i\")\n",
    "    if same_name.Actor_name.nunique() > 1:\n",
    "        print(\"Freebase id: \", i, \" | names: \", same_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter characters metadata dataframe to keep only the characters where the character name and actor name are not null\n",
    "characters_before_filter = character_metadata.shape[0]\n",
    "character_metadata = character_metadata[character_metadata['Freebase_actor_ID'].notnull()]\n",
    "# show how many characters were originally in the dataframe, how many were removed and how many are left\n",
    "print('Number of characters before filter: ', characters_before_filter)\n",
    "print('Number of characters after filter: ', character_metadata.shape[0])\n",
    "print('Number of characters removed: ', characters_before_filter - character_metadata.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>\n",
    "        Check utility of filtering actors\n",
    "        <br>for movies: normal to have > and not >= ?\n",
    "    </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need movies that have at least 2 actors to connect the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the characters of each movie in a list and the actors of each movie in a list\n",
    "actors = character_metadata.groupby('Wikipedia_movie_ID')['Actor_name'].apply(list).reset_index().rename(columns={'Actor_name': 'Actors_names'})\n",
    "# count the actors of each movie\n",
    "actors['Number_of_actors'] = actors['Actors_names'].apply(lambda x: len(x))\n",
    "# filter the actors dataframe to keep only the movies with more than 2 actors\n",
    "actors = actors[actors['Number_of_actors'] > 2].reset_index(drop=True)\n",
    "# show the number of movies before and after the filter and how many movies were removed\n",
    "print('Number of movies before filter: ', character_metadata['Wikipedia_movie_ID'].nunique())\n",
    "print('Number of movies after filter: ', actors.shape[0])\n",
    "print('Number of movies removed: ', character_metadata['Wikipedia_movie_ID'].nunique() - actors.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Further exploration of cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have drop the data that won't be usefull we can start analysing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly print the new dataframe merging movies and actors\n",
    "actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.displot(actors['Wikipedia_movie_ID'], x = actors['Number_of_actors'],\n",
    "                   log=True, discrete=True, aspect = 3)\n",
    "plot = plot.set(title = 'Distribution of the number of actors per movie', \n",
    "               xlabel = 'Number of actors',\n",
    "               ylabel = 'Number of movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating a network of actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to creat a first network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one actor per line in the new dataframe\n",
    "actors_new_meta = actors.merge(character_metadata[['Character_name', 'Actor_name', 'Wikipedia_movie_ID']], on='Wikipedia_movie_ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_new_meta.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with pairs of actors and the number of movies they acted in together\n",
    "# the dataframe to merge contains all the actors_new_meta dataframe except the actors_names column\n",
    "to_merge = actors_new_meta.drop('Actors_names', axis=1)\n",
    "actors_pairs = to_merge.merge(to_merge, on=['Wikipedia_movie_ID', 'Number_of_actors'], how='inner')\n",
    "# filter the dataframe to keep only the pairs where the actor names are different\n",
    "actors_pairs = actors_pairs[actors_pairs['Actor_name_x'] != actors_pairs['Actor_name_y']]\n",
    "# filter the dataframe to keep only the pairs that are not interchangeable (actor1, actor2) and (actor2, actor1)\n",
    "actors_pairs = actors_pairs[actors_pairs['Actor_name_x'] < actors_pairs['Actor_name_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each pair make a new column with the list of movies they acted in together\n",
    "actors_pairs_common_movies = actors_pairs.groupby(['Actor_name_x', 'Actor_name_y'])['Wikipedia_movie_ID'].apply(list).reset_index().rename(columns={'Wikipedia_movie_ID': 'Common_movies'})\n",
    "# remove the duplicates in the movies list\n",
    "actors_pairs_common_movies['Common_movies'] = actors_pairs_common_movies['Common_movies'].apply(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of common movies between each pair of actors\n",
    "actors_pairs_common_movies['Number_of_common_movies'] = actors_pairs_common_movies['Common_movies'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataframe to keep only the pairs that acted in more than 2 movies together\n",
    "actors_pairs_common_movies_filtered = actors_pairs_common_movies[actors_pairs_common_movies['Number_of_common_movies'] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_pairs_common_movies_filtered.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Creating the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to create networks, a really common one is the networkx library. It offers lots of tools and we can easily find documentation on the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a non directed graph from the dataframe\n",
    "G = nx.from_pandas_edgelist(actors_pairs_common_movies_filtered, source='Actor_name_x', target='Actor_name_y', edge_attr='Number_of_common_movies')\n",
    "# show the number of nodes and edges in the graph\n",
    "print('Number of nodes: ', G.number_of_nodes())\n",
    "print('Number of edges: ', G.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the network we'll need to analyse it. The first step is to create subgroup using the louvain algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make partitions of the graph \n",
    "coms = algorithms.louvain(G, weight='Number_of_common_movies')\n",
    "\n",
    "# make subgraphs from the partitions\n",
    "subgraphs = [G.subgraph(c) for c in coms.communities]\n",
    "# show the number of subgraphs\n",
    "print('Number of communities: ', len(subgraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the number of nodes in each subgraph and the average weight of the edges in each subgraph\n",
    "for i, subgraph in enumerate(subgraphs):\n",
    "    print('community ', i + 1, ' number of actors: ', subgraph.number_of_nodes())\n",
    "    print('community ', i + 1, ' average numbers of movies between actors: ', subgraph.size(weight='Number_of_common_movies') / subgraph.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Vizualising the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start the funny part with a basic visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualise the obtained partitions (top 20 communities)\n",
    "viz.plot_network_clusters(G, coms, node_size=20, figsize=(20, 20), plot_labels=False, top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_community_graph(G, coms, node_size=20, figsize=(20, 20), plot_labels=False, top_k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Analysing subnetworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we aim to see tendancies between those subgroup, we'll need to add features to nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in G.nodes:\n",
    "    G.nodes[n]['actor_gender'] = character_metadata[character_metadata.Actor_name == n]['actor_gender'].iloc[0]\n",
    "    G.nodes[n]['Actor_ethnicity'] = character_metadata[character_metadata.Actor_name == n]['Actor_ethnicity'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the assortativity  for certains properties. It measures the similarity of connections in the graph with respect to the given attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"gender homophily: \", nx.attribute_assortativity_coefficient(G, 'actor_gender'))\n",
    "print(\"ethnicity homophily: \", nx.attribute_assortativity_coefficient(G, 'Actor_ethnicity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the top 20 communities in dataframes\n",
    "# each row in the dataframe is an actor in the community, the connectivity column represents the total weight of the edges that the actor is connected to\n",
    "# i.e the total number of movies the actor acted in with the other actors in the community\n",
    "top_20_communities = []\n",
    "for i, subgraph in enumerate(subgraphs[:20]):\n",
    "    top_20_communities.append(pd.DataFrame(subgraph.degree(weight='Number_of_common_movies'), columns=['Actor_name', 'connectivity']).sort_values('connectivity', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each community add columns for actors ethnicity, gender and date of birth from the character_metadata dataframe\n",
    "for i, community in enumerate(top_20_communities):\n",
    "    top_20_communities[i] = community.merge(character_metadata[['Actor_name','actor_gender', 'Actor_date_of_birth', 'Actor_ethnicity']], on='Actor_name', how='inner').drop_duplicates(subset=['Actor_name']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.connected_watts_strogatz_graph(30,5,.2)\n",
    "nodes = G.nodes()\n",
    "edges=list(G.edges(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d37a1d50f378da0f68e11ee5fba6c6e83e272cf9b6bb98807c67244994dff8ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
